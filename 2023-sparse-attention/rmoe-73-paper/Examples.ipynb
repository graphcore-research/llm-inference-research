{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "import llminference as L\n",
    "\n",
    "api = wandb.Api()\n",
    "def get_run(id: str) -> wandb.apis.public.Run:\n",
    "    return api.run(f\"research/sparse-attention/runs/{id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Figures.ipynb\n",
    "run_ids = {'cnn_dailymail': ['vwnh8cu6', '539f9rom', '82e0zahq', 'lbpj144w'],\n",
    " 'repetition': ['wez29r4a', '3myiq6s1', 'tyhsk7u3', '4kuqkuvs'],\n",
    " 'squad': ['u65h4c6x', 's73en2vc', 'tiv7kxft', 'rhc29d4t'],\n",
    " 'triviaqa': ['cjcx2ccn', 'h08zynp0', 's3har2ni', 'i1klec42'],\n",
    " 'wikitext_bpc': ['xxlf2lqq', 'z1fclt4r', 'nwepshqs', 'zelxigof']}\n",
    "\n",
    "display_name = dict(\n",
    "    dense=\"DENSE\",\n",
    "    ann=\"SPARQ\",\n",
    "    eviction=\"H2O\",\n",
    "    local=\"LOCAL\",\n",
    ")\n",
    "\n",
    "for _, ids in run_ids.items():\n",
    "    ids.sort(key=lambda id: list(display_name.keys()).index(get_run(id).config[\"sparsity\"][\"name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(text: str, length: int) -> str:\n",
    "    return text if len(text) <= length else text[:length] + \"...\"\n",
    "\n",
    "def show_example(example: Dict[str, Any], task: str):\n",
    "    results = []\n",
    "    for id in run_ids[task]:\n",
    "        m = [r for r in get_run(id).summary.results if r[\"id\"] == example[\"id\"]]\n",
    "        if len(m) > 2 if task == \"triviaqa\" else len(m) != 1:\n",
    "            raise ValueError(f\"Multiple matching results for {example['id']}\")\n",
    "        results.append(m[0])\n",
    "\n",
    "    key = dict(squad=\"match\", triviaqa=\"match\", cnn_dailymail=\"rougeL\", wikitext_bpc=\"bpc\", repetition=\"match_length_char\")[task]\n",
    "    print({get_run(id).config[\"sparsity\"][\"name\"]: r[key] for id, r in zip(run_ids[task], results)})\n",
    "    print()\n",
    "    print(f\"### PROMPT ({example['id']})\")\n",
    "    if task == \"cnn_dailymail\":\n",
    "        print(shorten(example[\"context\"], 80) + L.summarisation.DEFAULT_PROMPT)\n",
    "    elif task == \"repetition\":\n",
    "        offset = example[\"context\"].index(example[\"prompt\"])\n",
    "        lines = example[\"context\"].split(\"\\n\")\n",
    "        line_offset = np.cumsum([len(line) + 1 for line in lines])\n",
    "        line_index = (line_offset < offset).sum()\n",
    "        print(\"\\n\".join(lines[:2] + [\"...\", \"...\"] + lines[line_index:][:10] + [\"...\", \"...\"])\n",
    "              + L.repetition.PROMPT_PREFIX + example[\"prompt\"])\n",
    "    elif task == \"triviaqa\":\n",
    "        lines = example[\"context\"].replace(\"\\n\\n\", \"\\n\").split(\"\\n\")\n",
    "        print(\"\\n\".join(shorten(s, 50) for s in lines[:5] + [\"...\", \"...\"] + lines[-5:]))\n",
    "        print(example[\"prompt\"])\n",
    "    elif task == \"squad\":\n",
    "        lines = example[\"context\"].split(\"\\n\")\n",
    "        print(\"\\n\".join(shorten(s, 50) for s in lines[:-1]) + \"\\n\" + lines[-1])\n",
    "        print(example[\"prompt\"])\n",
    "    print()\n",
    "    print(\"### OUTPUT\")\n",
    "    for id, result in zip(run_ids[task], results):\n",
    "        out = shorten(result[\"output\"].split(\"\\n\")[0], 80)\n",
    "        print(f'{display_name[get_run(id).config[\"sparsity\"][\"name\"]]:>5}: {out}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/nethome/douglaso/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8743a730c2a94b51afb423668e62319c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /nethome/douglaso/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-03400b5d173ab796.arrow\n",
      "Loading cached shuffled indices for dataset at /nethome/douglaso/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-c374d8616db3e9e0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense': True, 'ann': True, 'eviction': False, 'local': False}\n",
      "\n",
      "### PROMPT (56de0ed14396321400ee257b)\n",
      "Title: Private school. Background: In many parts o...\n",
      "Title: University of Chicago. Background: The Univ...\n",
      "Title: Nikola Tesla. Background: Near the end of h...\n",
      "Title: Ctenophora. Background: Since all modern ct...\n",
      "Title: Chloroplast. Background: Lepidodinium virid...\n",
      "Title: Construction. Background: Construction proj...\n",
      "Title: Normans. Background: Institutionally, the N...\n",
      "Title: Genghis Khan. Background: At this time, non...\n",
      "From what you've just read about Normans, please answer the following questions.\n",
      "Question: What does Kitab Rudjdjar mean in English?\n",
      "Answer: The Book of Roger\n",
      "Question: What kind of bureaucracy did the Normans institute?\n",
      "Answer:\n",
      "\n",
      "### OUTPUT\n",
      "DENSE: Meritocratic\n",
      "SPARQ: Meritocratic\n",
      "  H2O: Mer Mer Mer Mer Mer Mer Mer Mer Mer\n",
      "LOCAL: Feudalism\n"
     ]
    }
   ],
   "source": [
    "index = 18\n",
    "show_example(\n",
    "    L.qa.add_few_shot_prompt(L.qa.SQuAD.data()[index], k=1, prompt_template=L.qa.get_default_prompt_template(\"meta-llama/Llama-2-7b-hf\", shots=1)),\n",
    "    \"squad\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trivia_qa (/nethome/douglaso/.cache/huggingface/datasets/trivia_qa/rc/1.2.0/ee76d8a9403e71177e2a3fa7e414d1ee28a79a0970d9176f62f268798aa64b31)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b80450442b84468bf189ccdc669a696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /nethome/douglaso/.cache/huggingface/datasets/trivia_qa/rc/1.2.0/ee76d8a9403e71177e2a3fa7e414d1ee28a79a0970d9176f62f268798aa64b31/cache-a997c05712301d33.arrow\n",
      "Loading cached shuffled indices for dataset at /nethome/douglaso/.cache/huggingface/datasets/trivia_qa/rc/1.2.0/ee76d8a9403e71177e2a3fa7e414d1ee28a79a0970d9176f62f268798aa64b31/cache-49a4e46d67c5b9d0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense': True, 'ann': True, 'eviction': True, 'local': False}\n",
      "\n",
      "### PROMPT (dpql_5685)\n",
      "Apéritifs and digestifs ( and) are drinks, typical...\n",
      "Apéritifs\n",
      "An apéritif is an alcoholic beverage usually serve...\n",
      "\"Apéritif\" may also refer to a snack that precedes...\n",
      "\"Apéritif\" is a French word derived from the Latin...\n",
      "...\n",
      "...\n",
      "* Distilled liquors (ouzo, tequila, whisky or akva...\n",
      "* Liquor cocktails (Black Russian, Rusty Nail, etc...\n",
      "In certain areas, it is not uncommon for a digesti...\n",
      "Bitter digestifs typically contain carminative her...\n",
      "In many countries, people drink alcoholic beverage...\n",
      "Question: Which aperitif is named for the Paris chemist who created it in 1846?\n",
      "Answer:\n",
      "\n",
      "### OUTPUT\n",
      "DENSE: Dubonnet\n",
      "SPARQ: Dubonnet\n",
      "  H2O: Dubonnet\n",
      "LOCAL: Vermouth.\n"
     ]
    }
   ],
   "source": [
    "index = 9\n",
    "example = L.qa.add_few_shot_prompt(L.qa.TriviaQA.data(context=\"wiki\")[index], k=0, prompt_template=L.qa.get_default_prompt_template(\"meta-llama/Llama-2-7b-hf\", shots=0))\n",
    "show_example(example, \"triviaqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN/DailyMail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/nethome/douglaso/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed0b30b6e444155898d3fa377fbc964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /nethome/douglaso/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de/cache-14745bd540514b27.arrow\n",
      "Loading cached shuffled indices for dataset at /nethome/douglaso/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de/cache-e1812a493f78a625.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense': 0.15172413793103448, 'ann': 0.15894039735099338, 'eviction': 0.19736842105263155, 'local': 0.09599999999999999}\n",
      "\n",
      "### PROMPT (417e9c57edd888a811e860429219b3a66f16d92c)\n",
      "Article: Being at Old Trafford on Saturday was a surreal experience – and I’m no...\n",
      "Summary:\n",
      "\n",
      "### OUTPUT\n",
      "DENSE: Manchester United fans have been left frustrated by the club's lack of attacking...\n",
      "SPARQ: Manchester United fans have been left frustrated by the team's performances this...\n",
      "  H2O: Manchester United fans are not happy with the team's performance this season. Th...\n",
      "LOCAL: The rebuild is underway. But it’s unfair to expect 'Fergie football' so soon.\n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "show_example(L.summarisation.CnnDailymail.data()[index], \"cnn_dailymail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tiny_shakespeare (/nethome/douglaso/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/b5b13969f09fe8707337f6cb296314fbe06960bd9a868dca39e713e163d27b5e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417614eb94434b14a3fc44e0cde95954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense': 258, 'ann': 254, 'eviction': 5, 'local': 0}\n",
      "\n",
      "### PROMPT (5049)\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "...\n",
      "...\n",
      "Our steed the leg, the tongue our trumpeter.\n",
      "With other muniments and petty helps\n",
      "In this our fabric, if that they--\n",
      "\n",
      "MENENIUS:\n",
      "What then?\n",
      "'Fore me, this fellow speaks! What then? what then?\n",
      "\n",
      "First Citizen:\n",
      "Should by the cormorant belly be restrain'd,\n",
      "...\n",
      "...\n",
      " the tongue our trumpeter.\n",
      "With other muniments and petty helps\n",
      "In this our fabric, if that they--\n",
      "\n",
      "MENENIUS:\n",
      "What then?\n",
      "'Fore me,\n",
      "\n",
      "### OUTPUT\n",
      "DENSE: this fellow speaks! What then? what then?\n",
      "SPARQ: this fellow speaks! What then? what then?\n",
      "  H2O: this is most\n",
      "LOCAL: I cannot tell.\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "show_example(L.repetition.Shakespeare.data()[index], \"repetition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiText BPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext_document_level (/nethome/douglaso/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-103-raw-v1/1.0.0/c7f10a7786444f898dd236db33d4bee9b130f8cbcac690e7bde9b0d027e19fc1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c18294b981b4b21b190e3a12a9b4037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /nethome/douglaso/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-103-raw-v1/1.0.0/c7f10a7786444f898dd236db33d4bee9b130f8cbcac690e7bde9b0d027e19fc1/cache-0153ebe9c9b2083a.arrow\n",
      "Loading cached shuffled indices for dataset at /nethome/douglaso/.cache/huggingface/datasets/EleutherAI___wikitext_document_level/wikitext-103-raw-v1/1.0.0/c7f10a7786444f898dd236db33d4bee9b130f8cbcac690e7bde9b0d027e19fc1/cache-9e9e22ca5a4dc438.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{verbatim}### QUERY (0)\n",
      "\n",
      " = County Road 595 ( Marquette County , Michigan ) = \n",
      " \n",
      " County Road 595 ( CR 595 , Co . Rd . 595 ) is a proposed primary county road in...\n",
      " In 2003 , a flood along the Dead River destroyed or forced the closure of sever...\n",
      " The Marquette County Road Commission ( MCRC ) applied for permits from the stat...\n",
      " \n",
      " = = Route description = = \n",
      " \n",
      " The county road would start at its southern end at an intersection with US 41 /...\n",
      " \n",
      " = = History = = \n",
      " \n",
      " \n",
      " = = = Background = = = \n",
      " \n",
      " On May 14 , 2003 , a section of the Silver Lake Dam failed in northwestern Marq...\n",
      "\\end{verbatim}\n",
      "\\ Since the flood a new , roughly 100 @-@ foot @-@ tall ( 30 m ) bridge{\\color{blue}\\ has been constructed on CR 510 , ensuring that any future flooding on the Dead River would not necessitate closure of the modern bridge . This structure was built at that height in order to benefit commercial interests in the area , as well as to provide the area with reliable public and emergency access . \n",
      " Rio Tinto Group , the British @-@ based parent company of Kennecott Minerals received permission}\n",
      "\\begin{verbatim}### BPC\n",
      "DENSE: 0.788\n",
      "SPARQ: 0.790\n",
      "  H2O: 0.859\n",
      "LOCAL: 0.904\n",
      "\\end{verbatim}\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "example = L.bpc.WikiText.data()[index]\n",
    "lines = example[\"prefill\"].split(\"\\n\")\n",
    "print(f\"\\\\begin{{verbatim}}### QUERY ({index})\")\n",
    "print()\n",
    "print(\"\\n\".join([shorten(line, 80) for line in lines[:-1]]))\n",
    "print(\"\\\\end{verbatim}\")\n",
    "print(\"\\\\\" + lines[-1] + \"{\\color{blue}\\\\\" + example[\"reference\"] + \"}\")\n",
    "print(\"\\\\begin{verbatim}### BPC\")\n",
    "for id in run_ids[\"wikitext_bpc\"]:\n",
    "    run = get_run(id)\n",
    "    bpc = run.summary.results[index][\"bpc\"]\n",
    "    print(f'{display_name[get_run(id).config[\"sparsity\"][\"name\"]]:>5}: {bpc:.3f}')\n",
    "print(\"\\\\end{verbatim}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
