{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llminference as L\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"lmsys/vicuna-7b-v1.5-16k\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'confusion_contexts': 3, 'mean_length': 830},\n",
       " {'confusion_contexts': 7, 'mean_length': 1590},\n",
       " {'confusion_contexts': 15, 'mean_length': 3102},\n",
       " {'confusion_contexts': 31, 'mean_length': 6134},\n",
       " {'confusion_contexts': 63, 'mean_length': 12187}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tasks = []\n",
    "for confusion_contexts in [3, 7, 15, 31, 63]:\n",
    "    data = L.tasks.qa.SQuAD.data(part=\"train\", confusion_contexts=confusion_contexts)\n",
    "    examples = [L.tasks.qa.add_few_shot_prompt(data[i], k=1, prompt_template=L.tasks.qa.get_default_prompt_template(config_name, shots=1))\n",
    "                for i in range(1000)]\n",
    "    tasks.append(dict(\n",
    "        confusion_contexts=confusion_contexts,\n",
    "        mean_length=int(sum(len(tokenizer.tokenize(x[\"context\"] + x[\"prompt\"])) for x in examples) / len(examples)),\n",
    "    ))\n",
    "display(tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
